{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f9fc2a-cfe4-4e62-930a-315e50551477",
   "metadata": {},
   "source": [
    "# Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97171ff4-9f11-4194-bed8-c5643ab80395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "import drms\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255754f-c215-47c5-82ba-4e170dd1097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Turn off tqdm\n",
    "# from functools import partialmethod\n",
    "# tqdm.__init__ = partialmethod(tqdm.__init__, disable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7cda0d-6a69-4ab4-9868-a694a4e9b7a0",
   "metadata": {},
   "source": [
    "# Define auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b00da78-095c-4772-b918-27d4d32a3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utility Functions ##\n",
    "def mkdir(a_dir):\n",
    "    if(not os.path.exists(a_dir)):\n",
    "        os.makedirs(a_dir)          \n",
    "    \n",
    "def write_csv(file_name, function_csv, data, header=False):\n",
    "    with open(file_name, function_csv) as f:\n",
    "        writer = csv.writer(f,lineterminator='\\n')\n",
    "        if header:\n",
    "            writer.writerow(header)\n",
    "        writer.writerow(data)    \n",
    "        \n",
    "def read_csv(csv_path):\n",
    "    with open(csv_path, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(reader)    \n",
    "    return data        \n",
    "\n",
    "def write_txt(txt_path, function_txt_downloaded_flares, flare_id, header=False):\n",
    "    if function_txt_downloaded_flares=='w':\n",
    "        with open(txt_path, function_txt_downloaded_flares) as f:\n",
    "            f.write(header)\n",
    "            f.write('\\n')\n",
    "            f.write(flare_id)\n",
    "            f.write('\\n')\n",
    "    else:\n",
    "        with open(txt_path, function_txt_downloaded_flares) as f:\n",
    "            f.write(flare_id)\n",
    "            f.write('\\n')\n",
    "\n",
    "def read_txt(txt_path):\n",
    "    lines = []\n",
    "    with open(txt_path) as f:\n",
    "        for line in f:\n",
    "            lines.append(line.replace(\"\\r\", \"\").replace(\"\\n\", \"\"))\n",
    "    return lines\n",
    "            \n",
    "            \n",
    "def convert_time_format(cur_time, offset=0):\n",
    "    # offset: current - or + certain minutes\n",
    "    #         e.g., start_time - 15: offset=-15\n",
    "    temp = datetime.strptime(cur_time, '%Y-%m-%d %H:%M:%S') + timedelta(minutes = offset)\n",
    "    temp = temp.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "    return temp\n",
    "\n",
    "        \n",
    "def write_csv_event(file_name, flare_id, goes_class, noaa_active_region, primary_verified, \n",
    "                    secondary_verified, x_hpc, y_hpc, start_time, end_time, peak_time, \n",
    "                    tref, delta_t, n_pixel):\n",
    "    \n",
    "    header_csv = ['flare_id', 'goes_class', 'noaa_active_region', 'primary_verified', \n",
    "                  'secondary_verified', 'x_hpc', 'y_hpc', 'start_time_flare', 'end_time_flare', \n",
    "                  'peak_time_flare', 'tref', 'delta_t', 'n_pixel']\n",
    "\n",
    "    data = [flare_id, goes_class, noaa_active_region, primary_verified, \n",
    "            secondary_verified, x_hpc, y_hpc, start_time, end_time, peak_time, \n",
    "            tref, delta_t, n_pixel]\n",
    "\n",
    "    function_csv = 'w'\n",
    "\n",
    "    with open(file_name, function_csv, encoding='UTF8', newline='') as file_csv:\n",
    "\n",
    "            writer = csv.writer(file_csv)\n",
    "            writer.writerow(header_csv)\n",
    "            writer.writerow(data)\n",
    "\n",
    "# download aia images through drms\n",
    "def download_aia_images(tref, delta_t, x_hpc, y_hpc, n_pixel,\n",
    "                        path_dir='./', notify='john_doe@something.com'):\n",
    "    \n",
    "    client = drms.Client(verbose=False)\n",
    "    \n",
    "    qstr = \"aia.lev1_euv_12s[\"+ tref +\"/\" + str(delta_t) + \"m]\"\n",
    "    print(f\"Data export query:\\n  {qstr}\\n\")\n",
    "\n",
    "    ###############################################################################\n",
    "    # Construct the dictionary specifying that we want to request a cutout.\n",
    "    # This is done via the ``im_patch`` command.\n",
    "    \n",
    "    # The ``t`` controls whether tracking is disabled (``1``) or enabled (``0``).\n",
    "    # ``r`` controls the use of sub-pixel registration.\n",
    "    # ``c`` controls whether off-limb pixels are filled with NaNs.\n",
    "    # For additional details about ``im_patch``, \n",
    "    # see the `documentation <http://jsoc.stanford.edu/doxygen_html/group__im__patch.html>`_.\n",
    "    process = {\n",
    "        \"aia_scale_aialev1\":{           # Scale for transforming data as level 1p5\n",
    "        \"mpt\": \"aia.master_pointing3h\",\n",
    "        },\n",
    "        \"im_patch\": {\n",
    "            \"t_ref\": tref,\n",
    "            \"t\": 1,\n",
    "            \"r\": 0,\n",
    "            \"c\": 0,\n",
    "            \"locunits\": \"arcsec\",\n",
    "            \"boxunits\": \"pixels\",\n",
    "            \"x\": x_hpc,\n",
    "            \"y\": y_hpc,\n",
    "            \"width\": n_pixel,\n",
    "            \"height\": n_pixel,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Submit export request using the 'fits' protocol\n",
    "    print(\"Submitting export request...\")\n",
    "    result = client.export(\n",
    "        qstr,\n",
    "        method=\"url\",\n",
    "        protocol=\"fits\",\n",
    "        email=notify,\n",
    "        process=process,\n",
    "        filenamefmt=\"{seriesname}.{T_REC:A}.{WAVELNTH}.{segment}\",\n",
    "    )\n",
    "\n",
    "    # Print request URL.\n",
    "    print(f\"\\nRequest URL: {result.request_url}\")\n",
    "    print(f\"{int(len(result.urls))} file(s) available for download.\\n\")\n",
    "\n",
    "    # Download selected files.\n",
    "    result.wait()\n",
    "    result.download(path_dir)\n",
    "    print(\"Download finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512eab70-de8f-42b3-bda2-08cd3cba5b33",
   "metadata": {},
   "source": [
    "# Define main function for downloading AIA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3951ee09-5fd6-4f3d-8b58-b48c438c83b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_single_event(flare_id, goes_class, noaa_active_region, primary_verified, secondary_verified, \n",
    "                          x_hpc, y_hpc, start_time, end_time, peak_time, tref, \n",
    "                          delta_t, n_pixel, aia_fits_folder, notify, downloaded_flares):\n",
    "    \n",
    "                          \n",
    "\n",
    "    print('*********\\nStart time:', datetime.now())\n",
    "    print('Working on flare: \"%s\"' %flare_id)\n",
    "    \n",
    "    ## Check if the flare is downloaded ##\n",
    "    if(flare_id in downloaded_flares):\n",
    "        print('The flare has been downloaded before.')\n",
    "        print('Completed!')\n",
    "        print('End time:', datetime.now())\n",
    "        s = '[Error Code: -1] The flare has been downloaded before'\n",
    "        return -1, s, flare_id\n",
    "      \n",
    "    print('Dowloading AIA data...', datetime.now())\n",
    "    \n",
    "    ## Create folder for this event\n",
    "    event_folder = os.path.join(aia_fits_folder,flare_id)\n",
    "    mkdir(event_folder)\n",
    "    \n",
    "    download_aia_images(tref, delta_t, x_hpc, y_hpc, n_pixel, path_dir=event_folder, notify=notify)\n",
    "\n",
    "    \n",
    "    file_name = os.path.join(event_folder, flare_id + \"_data.csv\")\n",
    "    \n",
    "    write_csv_event(file_name, flare_id, goes_class, noaa_active_region, primary_verified, \n",
    "                    secondary_verified, x_hpc, y_hpc, start_time, end_time, peak_time, \n",
    "                    tref, delta_t, n_pixel)\n",
    "        \n",
    "    print('End time:', datetime.now())\n",
    "    print()\n",
    "    \n",
    "    return 0, '', flare_id "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023b4c88-b49d-4aad-8e6e-7aca078389ed",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f49e90-bf74-4835-8360-567a779696a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \".\"\n",
    "\n",
    "data_dir     = os.path.join(project_dir, \"data\") # parent dir for all data folders\n",
    "flare_lists_dir = os.path.join(data_dir, \"flare_lists\")\n",
    "\n",
    "aia_fits_folder = os.path.join(data_dir, \"aia_fits\")\n",
    "if not os.path.exists(aia_fits_folder):\n",
    "    os.mkdir(aia_fits_folder)\n",
    "\n",
    "# Setup Hyperparameters\n",
    "delta_t = 30 # in minutes\n",
    "n_pixel = 1000\n",
    "\n",
    "\n",
    "downloaded_flares_file = 'downloaded_flares.txt'\n",
    "notify = 'paolocrmassa@gmail.com' # please enter a valid email address for Jsoc\n",
    "flare_list = os.path.join(flare_lists_dir, \"flare_list_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2c46a6-1067-42cc-aef2-b457e7fd83a9",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8510016-5b07-4a1f-b533-53c2dc428c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = flare_list.find('flare_list_')\n",
    "flare_list_name = flare_list[idx:-4]\n",
    "\n",
    "flare_list_folder = os.path.join(aia_fits_folder, flare_list_name)\n",
    "\n",
    "# Create folder for this flare list\n",
    "if not os.path.exists(flare_list_folder):\n",
    "    os.mkdir(flare_list_folder)\n",
    "\n",
    "# Create metadata dir\n",
    "metadata_dir = os.path.join(flare_list_folder, \"metadata\")\n",
    "if not os.path.exists(metadata_dir):\n",
    "    os.mkdir(metadata_dir)\n",
    "\n",
    "# Load the list of downloaded flares\n",
    "# If such file does not exist, create an empty one\n",
    "downloaded_flares_path = os.path.join(metadata_dir, downloaded_flares_file)\n",
    "if(os.path.exists(downloaded_flares_path)):\n",
    "    downloaded_flares = read_txt(downloaded_flares_path)\n",
    "    function_txt_downloaded_flares = \"a\"\n",
    "else:\n",
    "    downloaded_flares = []\n",
    "    function_txt_downloaded_flares = \"w\"\n",
    "\n",
    "# Load previous log\n",
    "# If such file does not exist, create an empty one\n",
    "error_log_file_path = os.path.join(metadata_dir, 'error_log.csv')\n",
    "if(os.path.exists(error_log_file_path)):\n",
    "    function_csv_error_log = \"a\"\n",
    "else:\n",
    "    function_csv_error_log = \"w\"\n",
    "\n",
    "# Load the list of all flares that need to be downloaded\n",
    "flares = np.asarray(read_csv(flare_list)[1:])\n",
    "\n",
    "#for i in tqdm(range(len(flares)), disable=True):\n",
    "for i in range(len(flares):\n",
    "\n",
    "    flare_id, goes_class, noaa_active_region, primary_verified, secondary_verified, x_hpc, y_hpc, start_time, end_time, peak_time = flares[i]\n",
    "\n",
    "    # flare start and end times\n",
    "    flare_start = convert_time_format(start_time, 0)\n",
    "    flare_end   = convert_time_format(end_time, 0)\n",
    "    flare_peak  = convert_time_format(peak_time, 0)\n",
    "\n",
    "    # tref: start time of the data to be downloaded\n",
    "    tref   = convert_time_format(start_time, -delta_t)\n",
    "\n",
    "    try:\n",
    "        # download a flare\n",
    "        error_code, result, flare_id = download_single_event(flare_id, goes_class, noaa_active_region, primary_verified, secondary_verified, \n",
    "                                                             x_hpc, y_hpc, flare_start, flare_end, flare_peak, tref, \n",
    "                                                             delta_t, n_pixel, flare_list_folder, notify, downloaded_flares)\n",
    "\n",
    "        downloaded_flares.append(flare_id)\n",
    "\n",
    "        if error_code!=-1:\n",
    "            # write downladed flares to file\n",
    "            if function_txt_downloaded_flares==\"w\":\n",
    "                write_txt(downloaded_flares_path, function_txt_downloaded_flares, flare_id, header='flare_id')\n",
    "                function_txt_downloaded_flares=\"a\"\n",
    "            else:\n",
    "                write_txt(downloaded_flares_path, function_txt_downloaded_flares, flare_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        if function_csv_error_log==\"w\":\n",
    "            write_csv(error_log_file_path, function_csv_error_log, [flare_id, result], header=['flare_id','error'])\n",
    "            function_csv_error_log=\"a\"\n",
    "        else:\n",
    "            write_csv(error_log_file_path, function_csv_error_log, [flare_id, result])\n",
    "        pass\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"Sleep for 30s before the next request\")\n",
    "    time.sleep(30)\n",
    "    print(\"\")\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aia_env",
   "language": "python",
   "name": "aia_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
