{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa42012-2571-45b7-99a6-c7cf7b1ed2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pandas import *\n",
    "import numpy as np\n",
    "from astropy import time as time\n",
    "import astropy.units as u\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac7c5aa-77be-4fea-8a03-22fa27275dc3",
   "metadata": {},
   "source": [
    "# Read CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0edc16bb-3233-458d-a484-44f345bb7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.join(\".\",\"integrated_flare_data\")\n",
    "\n",
    "data = read_csv(os.path.join(folder,'goes_flares_integrated.csv'))\n",
    "\n",
    "flare_id           = np.array(data[\"flare_id\"])\n",
    "goes_class         = np.array(data[\"goes_class\"])\n",
    "noaa_active_region = np.array(data[\"noaa_active_region\"])\n",
    "hinode_ar          = np.array(data[\"hinode_ar\"])\n",
    "primary_verified   = np.array(data[\"primary_verified\"])\n",
    "secondary_verified = np.array(data[\"secondary_verified\"])\n",
    "start_time         = np.array(data[\"start_time\"])\n",
    "end_time           = np.array(data[\"end_time\"])\n",
    "peak_time          = np.array(data[\"peak_time\"])\n",
    "\n",
    "fl_loc_src         = np.array(data[\"fl_loc_src\"])\n",
    "goes_x_hpc         = np.array(data[\"x_hpc\"])\n",
    "goes_y_hpc         = np.array(data[\"y_hpc\"])\n",
    "ssw_x_hpc          = np.array(data[\"ssw_x_hpc\"])\n",
    "ssw_y_hpc          = np.array(data[\"ssw_y_hpc\"])\n",
    "hinode_x_hpc       = np.array(data[\"hinode_x_hpc\"])\n",
    "hinode_y_hpc       = np.array(data[\"hinode_y_hpc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eda33ce-01ed-4932-8db1-09695ced08d8",
   "metadata": {},
   "source": [
    "# Select flare location from provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2527b6e3-780a-40a4-80c7-eb7aed964ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hpc = np.zeros((len(goes_x_hpc),))\n",
    "y_hpc = np.zeros((len(goes_y_hpc),))\n",
    "\n",
    "idx_goes = np.where(fl_loc_src == 'GOES')\n",
    "idx_ssw  = np.where(fl_loc_src == 'SSW')\n",
    "idx_xrt  = np.where(fl_loc_src == 'XRT')\n",
    "\n",
    "# GOES\n",
    "x_hpc[idx_goes] = goes_x_hpc[idx_goes]\n",
    "y_hpc[idx_goes] = goes_y_hpc[idx_goes]\n",
    "\n",
    "# SSW\n",
    "x_hpc[idx_ssw] = ssw_x_hpc[idx_ssw]\n",
    "y_hpc[idx_ssw] = ssw_y_hpc[idx_ssw]\n",
    "\n",
    "# XRT\n",
    "x_hpc[idx_xrt] = hinode_x_hpc[idx_xrt]\n",
    "y_hpc[idx_xrt] = hinode_y_hpc[idx_xrt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26903679-5bc9-4f65-9782-49a9c00a4235",
   "metadata": {},
   "source": [
    "# Select start time after mid May 2010 \n",
    "(before that time, the SDO spacecraft location is not available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be4c6a6-9fe1-4f6e-aac8-09f290cd524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_time = time.Time('2010-05-15 00:00:00')\n",
    "\n",
    "cond_mid_may_2010   = []\n",
    "for i in range(len(start_time)):\n",
    "    \n",
    "    this_start_time = time.Time(start_time[i])\n",
    "    cond_mid_may_2010.append(this_start_time > ref_time)\n",
    "\n",
    "idx = np.where(np.array(cond_mid_may_2010))\n",
    "\n",
    "flare_id           = flare_id[idx]\n",
    "goes_class         = goes_class[idx]\n",
    "noaa_active_region = noaa_active_region[idx]\n",
    "hinode_ar          = hinode_ar[idx]\n",
    "primary_verified   = primary_verified[idx]\n",
    "secondary_verified = secondary_verified[idx]\n",
    "x_hpc              = x_hpc[idx]\n",
    "y_hpc              = y_hpc[idx]\n",
    "start_time         = start_time[idx]\n",
    "end_time           = end_time[idx]\n",
    "peak_time          = peak_time[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446e6116-f8a9-48d2-94ba-cb7c0f083f51",
   "metadata": {},
   "source": [
    "# Select where we have the same NOAA and Hinode information on AR number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f62d6305-f572-4c26-8e39-d0f288c39ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_noaa          = np.logical_not(np.isnan(noaa_active_region))\n",
    "cond_hinode        = np.logical_not(np.isnan(hinode_ar))\n",
    "idx                = np.where(cond_noaa & cond_hinode) \n",
    "\n",
    "flare_id           = flare_id[idx]\n",
    "goes_class         = goes_class[idx]\n",
    "noaa_active_region = noaa_active_region[idx]\n",
    "hinode_ar          = hinode_ar[idx]\n",
    "primary_verified   = primary_verified[idx]\n",
    "secondary_verified = secondary_verified[idx]\n",
    "x_hpc              = x_hpc[idx]\n",
    "y_hpc              = y_hpc[idx]\n",
    "start_time         = start_time[idx]\n",
    "end_time           = end_time[idx]\n",
    "peak_time          = peak_time[idx]\n",
    "\n",
    "idx = np.where(noaa_active_region==hinode_ar)\n",
    "flare_id           = flare_id[idx]\n",
    "goes_class         = goes_class[idx]\n",
    "noaa_active_region = noaa_active_region[idx]\n",
    "primary_verified   = primary_verified[idx]\n",
    "secondary_verified = secondary_verified[idx]\n",
    "x_hpc              = x_hpc[idx]\n",
    "y_hpc              = y_hpc[idx]\n",
    "start_time         = start_time[idx]\n",
    "end_time           = end_time[idx]\n",
    "peak_time          = peak_time[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a7820-89c7-46d7-81f4-329ef62f9653",
   "metadata": {},
   "source": [
    "# Select only primary or secondary verified events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c46404b7-830a-45db-8972-f6f4c0287e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx                = np.where(primary_verified | secondary_verified)\n",
    "\n",
    "flare_id           = flare_id[idx]\n",
    "goes_class         = goes_class[idx]\n",
    "noaa_active_region = noaa_active_region[idx]\n",
    "primary_verified   = primary_verified[idx]\n",
    "secondary_verified = secondary_verified[idx]\n",
    "x_hpc              = x_hpc[idx]\n",
    "y_hpc              = y_hpc[idx]\n",
    "start_time         = start_time[idx]\n",
    "end_time           = end_time[idx]\n",
    "peak_time          = peak_time[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97968294-d68e-4dea-8e28-d37e0827ab9d",
   "metadata": {},
   "source": [
    "# Select flares for which fl_lon and fl_lat are not Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c050fb1-f9ab-499a-b6e3-6b2bbeee90dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_x_hpc         = np.logical_not(np.isnan(x_hpc))\n",
    "cond_y_hpc         = np.logical_not(np.isnan(y_hpc))\n",
    "idx                = np.where(cond_x_hpc & cond_y_hpc) \n",
    "\n",
    "flare_id           = flare_id[idx]\n",
    "goes_class         = goes_class[idx]\n",
    "noaa_active_region = noaa_active_region[idx]\n",
    "primary_verified   = primary_verified[idx]\n",
    "secondary_verified = secondary_verified[idx]\n",
    "x_hpc              = x_hpc[idx]\n",
    "y_hpc              = y_hpc[idx]\n",
    "start_time         = start_time[idx]\n",
    "end_time           = end_time[idx]\n",
    "peak_time          = peak_time[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2930b8b1-4f4b-4d50-ac32-456ad1c70a17",
   "metadata": {},
   "source": [
    "# Check that difference between start time of a flare and end time of the previous one is greater than 30 min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93384b70-0dda-48da-b40e-6a1ae1c60fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_check = start_time[1:]\n",
    "end_time_check   = end_time[:-1]\n",
    "\n",
    "time_diff=[True]\n",
    "for i in range(len(start_time_check)):\n",
    "    \n",
    "    this_start_time_check = time.Time(start_time_check[i])\n",
    "    this_end_time_check   = time.Time(end_time_check[i])\n",
    "    this_diff = this_start_time_check - this_end_time_check\n",
    "    time_diff.append(this_diff > 30*u.min)\n",
    "    \n",
    "idx = np.where(np.array(time_diff))\n",
    "\n",
    "flare_id           = flare_id[idx]\n",
    "goes_class         = goes_class[idx]\n",
    "noaa_active_region = noaa_active_region[idx]\n",
    "primary_verified   = primary_verified[idx]\n",
    "secondary_verified = secondary_verified[idx]\n",
    "x_hpc              = x_hpc[idx]\n",
    "y_hpc              = y_hpc[idx]\n",
    "start_time         = start_time[idx]\n",
    "end_time           = end_time[idx]\n",
    "peak_time          = peak_time[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383944e0-a340-492d-a201-fcd0ee968dec",
   "metadata": {},
   "source": [
    "# Write csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cd0462b-464c-4244-be83-b1406d1cddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header of the CSV file\n",
    "header_csv = ['flare_id', 'goes_class', 'noaa_active_region', 'primary_verified', \n",
    "              'secondary_verified', 'x_hpc', 'y_hpc', 'start_time', 'end_time', 'peak_time']\n",
    "\n",
    "count_events      = 0\n",
    "count_flare_lists = 1\n",
    "\n",
    "while count_events < len(flare_id):\n",
    "    \n",
    "    csv_filename = os.path.join(folder,\"flare_list_\" + str(count_flare_lists) + \".csv\")\n",
    "    \n",
    "    count_this_list = 0\n",
    "    function_csv = 'w'\n",
    "    \n",
    "    while count_this_list < 100 and count_events < len(flare_id):\n",
    "        \n",
    "        data2store = [flare_id[count_events],          \n",
    "                      goes_class[count_events],\n",
    "                      int(noaa_active_region[count_events]),\n",
    "                      primary_verified[count_events],\n",
    "                      secondary_verified[count_events],\n",
    "                      x_hpc[count_events],\n",
    "                      y_hpc[count_events],\n",
    "                      start_time[count_events],\n",
    "                      end_time[count_events],\n",
    "                      peak_time[count_events]]\n",
    "    \n",
    "        # Store the data in the csv file\n",
    "        with open(csv_filename, function_csv, encoding='UTF8', newline='') as file_csv:\n",
    "            writer = csv.writer(file_csv)\n",
    "\n",
    "            # If new file, write the header\n",
    "            if function_csv == 'w':\n",
    "                writer.writerow(header_csv)\n",
    "\n",
    "            # Write the data\n",
    "            writer.writerow(data2store)\n",
    "\n",
    "            # Close file object\n",
    "            file_csv.close()\n",
    "\n",
    "        if function_csv == 'w':\n",
    "            function_csv = 'a'\n",
    "        \n",
    "        \n",
    "        count_this_list += 1\n",
    "        count_events += 1\n",
    "    \n",
    "    \n",
    "    count_flare_lists += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aia_env",
   "language": "python",
   "name": "aia_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
